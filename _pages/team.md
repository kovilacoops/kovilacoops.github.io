---
layout: archive
title: "Privacy & Security for User Communities"
permalink: /team/
author_profile: true
---

My team and I conduct user-centred/usable privacy and security research, with a focus on safeguarding privacy, safety and security of at-risk / vulnerable / minoritised users, communities, identities, or situations. We collaborate with researchers across disciplines, and stakeholders such as NGOs who support vulnerable and marginalised groups and victim-survivors, as well as digital safety advocacy, policy and industry. 
 
**Key features of our growing team**:
* We focus on empirical research at the intersection of privacy/security and HCI, behavioural and social sciences.
* We employ a mix of qualitative, quantitative, experimental, participatory and social science computational methods.
* We regularly feature articles at top-tier security and privacy publication venues, such as Usenix Security Symposium, ACM CCS and PETS. See selected publications [here](https://kovilacoops.github.io).
* We are currently based at King's College London.


 <!---📢🔔 **Currently Recruiting!** 👩‍🎓🧑‍🎓📚💼✍️ **1 Postdoctoral Research Associate, PhD Students, Research Interns. See** 👉 [Opportunities](https://kovilacoops.github.io/opportunities/) 




We conduct research across Privacy & Security for User Communities, under three main themes:
* **Inclusive privacy and security**

Privacy, security, digital safety are often designed for majority or WEIRD populations, thereby not appropriately serving all user communities (minority, with specific needs, or life situations), and risk discriminating access and appropriate engagement, while also creating concerns for them. We focus on at-risk communities, such as women, queer communities and children for e.g. in online platforms or digital-safety for socio-economically deprived communities. The [opportunities page](https://kovilacoops.github.io/opportunities/) further provides specific PhD/interns topics for this theme.


* **Mitigating technology-enabled harms**
  
There are growing examples of technology originally designed to enhance quality of life being mis-used to facilitate abuse, online harms and in-security. We investigate a particular context of technology-enabled harm in intersection with the user characteristic or life event that amplifies the chances of being targeted or in experiencing online harms (e.g. gender, age, life style preference, health condition in the context of smarthomes, intimate health care or online platforms). We aim to understand the lived experiences of users, make recommendations and prototype for safer/harm-mitigating experiences. The [opportunities page](https://kovilacoops.github.io/opportunities/) further provides specific PhD/interns topics for this theme.--->


<!--* **Private and safe chatbot interactions**

We will add this info soon.-->



Team members
------
* Jennifer Huang, PhD Student (2025~), first supervisor
* Chukwuka Jerahmeel Madumere, PhD Student (2024~), first supervisor
* Muhammad Abdul Basit Malik, PhD Student (2023~), second supervisor
* Shreenithi Suresh, MSc Student / Research Assistant (2023~)
* Killian Davitt, Postdoctoral Research Associate (Jan 2024 ~ Jun 2024 / AGENCY project)
* Mousa Jari, PhD student (2018-2024), first/second supervisor
* Uchechi Nwadike, PhD student (2015-2019), second supervisor
  

Recent Funded Projects 
------

<!--**Students**
* Athul, *MSc student, King's College London* (2022-2023)
* Gayda, *MSc student, King's College London* (2022-2023)
* Jyovita, *MSc student, King's College London* (2022-2023)
* Noura, *MSc student, King's College London* (2022-2023)
* Shreenithi, *MSc student, King's College London* (2022-2023)
* Dr. Uchechi Nwadike, *PhD student, Newcastle University* (2015-2019, Topic: How emotions impact privacy) *Second Supervisor*-->
   
**A selection of completed funded projects**
1. [AGENCY](https://agencyresearch.net): Assuring Citizen Agency in a World with Complex Online Harms. *Funded by the EPSRC* (Apr'22 - Mar'25), where my focus, as the King's College London Lead, was on the experiences of online harms in the (unconsensual) sharing of intimate content, as well as gender and sexuality with regards to online safety.
<!--2. and harm reduction mechanisms among marginalised communities, across contexts of Smarthomes, Femtech, Online Abuse and Digital Identities.AGENCY was a research consortium including colleagues from various disciplines based at Birmingham, Newcastle, Durham Universities, Royal Holloway University of London and King's College London. £3.5 million --> 

2. [Fintrust](https://fintrustresearch.com): Trust Engineering for the Financial Industry. *Funded by the EPSRC*. I focused on human-centred trust in AI, and worked closely with 3 postdocs to scope research and design user studies, as well as analyse and report data. (see postdoc section past postdoc members above).
3. Digital Technologies Power and Control, where I looked into how marginalised communities in the UK experience security, privacy, trustworthy and identity technologies. *Funded by SPRITE+ Network*. I worked with social science colleagues from the Open University and Sheffield University on exporatory work and conducted a few user and stakeholder workshops.
4. Revealing Young Learners' Mental Models of Online Sludge, where I focused on young learners' mental models of dark partterns online and inverventions to dispel misconceptions. *Funded by SPRITE+ Network*. Amongst various contributions, I particularly developed an analysis framework for analysing drawings from our participants, and contributed/co-led to the analysis/coding. I worked with colleagues from Strathclyde, Bath, Brunel, Bournemouth and Middlesex Universities.


**Postdocs we previously worked closely with**
* Dr Rui Huan, *Postdoc Newcastle University* (2022, Fintrust, Topic: Privacy Transparency in Chatbots, Methods: experimental and design work)
* Dr Jie Deng, *Postdoc Newcastle University* (2022, Fintrust, Topic: Trust in FinTech / AI, Method: large scale quantitative work)
* Dr. Ben Evans, *Postdoc The Open University* (2020 -2021, Digital Technologies Power and Control, Topic: Privacy, security & trust for marhinalised communities)
* Dr Magdalene Ng, *Postdoc Newcastle University* (2019 - 2021, Fintrust, Topic: Private, Secure, Trustworthy AI; Cybercrime experience, Method: research scoping, qualitative and quantitative user study designs)
